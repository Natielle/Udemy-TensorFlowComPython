{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neurais artificiais com a utilização de estimators\n",
    "\n",
    "O objetivo é conseguirmos predizer se a pessoa terá uma renda maior ou menor que 50 mil por ano.\n",
    "E vamos aplicar a RNA no banco de dados chamado 'census.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  final-weight   education  education-num  \\\n",
       "0   39          State-gov         77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors             13   \n",
       "2   38            Private        215646     HS-grad              9   \n",
       "3   53            Private        234721        11th              7   \n",
       "4   28            Private        338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loos  hour-per-week  native-country  income  \n",
       "0          2174             0             40   United-States   <=50K  \n",
       "1             0             0             13   United-States   <=50K  \n",
       "2             0             0             40   United-States   <=50K  \n",
       "3             0             0             40   United-States   <=50K  \n",
       "4             0             0             40            Cuba   <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo o banco de dados\n",
    "base = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# Para confirmarmos se está tudo certo com o banco olhamos o começinho dele.\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observando a quantidade de classes da coluna que queremos prever\n",
    "base['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para convertermos os labels em 0 e 1\n",
    "def converte_classe(rotulo):\n",
    "    if rotulo == ' >50K':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Então aplicamos a conversão do labels \n",
    "base.income = base.income.apply(converte_classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  final-weight   education  education-num  \\\n",
       "0   39          State-gov         77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors             13   \n",
       "2   38            Private        215646     HS-grad              9   \n",
       "3   53            Private        234721        11th              7   \n",
       "4   28            Private        338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loos  hour-per-week  native-country  income  \n",
       "0          2174             0             40   United-States       0  \n",
       "1             0             0             13   United-States       0  \n",
       "2             0             0             40   United-States       0  \n",
       "3             0             0             40   United-States       0  \n",
       "4             0             0             40            Cuba       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando a conversão\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos separar os atributos das labels \n",
    "X = base.drop('income', axis = 1) # Atributos\n",
    "Y = base.income                   # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "32556    0\n",
      "32557    1\n",
      "32558    0\n",
      "32559    0\n",
      "32560    1\n",
      "Name: income, Length: 32561, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as labels\n",
    "print(Y)\n",
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  final-weight   education  education-num  \\\n",
       "0   39          State-gov         77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors             13   \n",
       "2   38            Private        215646     HS-grad              9   \n",
       "3   53            Private        234721        11th              7   \n",
       "4   28            Private        338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loos  hour-per-week  native-country  \n",
       "0          2174             0             40   United-States  \n",
       "1             0             0             13   United-States  \n",
       "2             0             0             40   United-States  \n",
       "3             0             0             40   United-States  \n",
       "4             0             0             40            Cuba  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando os atributos\n",
    "print(type(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (22792, 14)\n",
      "X_test:  (9769, 14)\n",
      "Y_train:  (22792,)\n",
      "Y_test:  (9769,)\n"
     ]
    }
   ],
   "source": [
    "# Agora vamos separar o conjunto em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "# Analisando as dimensões\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"Y_train: \", Y_train.shape)\n",
    "print(\"Y_test: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'final-weight', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loos', 'hour-per-week', 'native-country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtem todas as colunas do conjunto de dados\n",
    "base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n",
       "       ' Never-worked'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora vamos ver todas as possibilidades de classes que o atributo workclass possui\n",
    "base.workclass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos criar as colunas categoricas utilizando o hash bucket\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(key = 'workclass', \n",
    "                                                                  hash_bucket_size = 100) # N° máx de categorias permitidas\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(key = 'education', hash_bucket_size = 100)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(key = 'marital-status', hash_bucket_size = 100)\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(key = 'occupation', hash_bucket_size = 100)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(key = 'relationship', hash_bucket_size = 100)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket(key = 'race', hash_bucket_size = 100)\n",
    "country = tf.feature_column.categorical_column_with_hash_bucket(key = 'native-country', hash_bucket_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a coluna sex de um jeito um pouco diferente (com vocabulary list)\n",
    "sex = tf.feature_column.categorical_column_with_vocabulary_list(key = 'sex', vocabulary_list=[' Male', ' Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como já definimos os atributos categóricos, vamos criar para os atributos numéricos\n",
    "age = tf.feature_column.numeric_column(key = 'age')\n",
    "final_weight = tf.feature_column.numeric_column(key = 'final-weight')\n",
    "education_num = tf.feature_column.numeric_column(key = 'education-num')\n",
    "capital_gain = tf.feature_column.numeric_column(key = 'capital-gain')\n",
    "capital_loos = tf.feature_column.numeric_column(key = 'capital-loos')\n",
    "hour = tf.feature_column.numeric_column(key = 'hour-per-week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "# Agora reunimos todas as colunas\n",
    "colunas = [age, workclass, final_weight, education, education_num,\n",
    "           marital_status, occupation, relationship, race, sex,\n",
    "           capital_gain, capital_loos, hour, country]\n",
    "print(colunas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos utilizar o estimator agora para implementarmos o modelo em si\n",
    "funcao_treinamento = tf.estimator.inputs.pandas_input_fn(x = X_train, y = Y_train,\n",
    "                                                        batch_size=32,# pega em lotes de 32\n",
    "                                                        num_epochs=None, # quantidade de vezes que vai rodar\n",
    "                                                        shuffle=True) # pega ordem aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Natielle\\AppData\\Local\\Temp\\tmp0eehsevf\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Natielle\\\\AppData\\\\Local\\\\Temp\\\\tmp0eehsevf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002208DD77518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Criando nosso modelo com DNN  (dense neural network), que é quando todos neurônios estão ligados a todos da próxima camada\n",
    "classificador = tf.estimator.DNNClassifier(hidden_units = [8, 8], # quantidade de camadas ocultas e qtde de neurônios em cada\n",
    "                                           feature_columns=colunas,  # passando as colunas\n",
    "                                           n_classes=2)  # maior que 50 mil ou menor. Temos duas categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Items of feature_columns must be a DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: HashedCategoricalColumn(key='education', hash_bucket_size=100, dtype=tf.string)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6f16542bd9ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Agora vamos fazer o treinamento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassificador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuncao_treinamento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1152\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1154\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1155\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    520\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m           batch_norm=batch_norm)\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m     super(DNNClassifier, self).__init__(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, use_tpu, batch_norm)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         batch_norm=batch_norm)\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_tpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[1;34m(features, mode)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         name='dnn')\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, hidden_units, feature_columns, activation_fn, dropout, input_layer_partitioner, batch_norm, name, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_column_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feature_column_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m       self._input_layer = feature_column_lib.DenseFeatures(\n\u001b[1;32m--> 129\u001b[1;33m           feature_columns=feature_columns, name='input_layer')\n\u001b[0m\u001b[0;32m    130\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m       self._input_layer = feature_column.InputLayer(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, feature_columns, trainable, name, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;34m'Items of feature_columns must be a DenseColumn. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[1;34m'You can wrap a categorical column with an '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m             'embedding_column or indicator_column. Given: {}'.format(column))\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Items of feature_columns must be a DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: HashedCategoricalColumn(key='education', hash_bucket_size=100, dtype=tf.string)"
     ]
    }
   ],
   "source": [
    "# Agora vamos fazer o treinamento\n",
    "classificador.train(input_fn = funcao_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Para não termos o erro acima, precisamos converter as colunas categóricas para valores embedded*\n",
    "\n",
    "Podemos ver como esse processo é feito com a imagem:\n",
    "![](embedding_column.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o Embedding\n",
    "embedded_workclass = tf.feature_column.embedding_column(workclass, \n",
    "                                                        # dimension é a quantidade de categorias da coluna \n",
    "                                                        dimension = len(base.workclass.unique()))\n",
    "embedded_education = tf.feature_column.embedding_column(education, dimension = len(base.education.unique()))\n",
    "embedded_marital = tf.feature_column.embedding_column(marital_status, dimension = len(base['marital-status'].unique()))\n",
    "embedded_occupation = tf.feature_column.embedding_column(occupation, dimension = len(base.occupation.unique()))\n",
    "embedded_relationship = tf.feature_column.embedding_column(relationship, dimension = len(base.relationship.unique()))\n",
    "embedded_race = tf.feature_column.embedding_column(race, dimension = len(base.race.unique()))\n",
    "embedded_sex = tf.feature_column.embedding_column(sex, dimension = len(base.sex.unique()))\n",
    "embedded_country = tf.feature_column.embedding_column(country, dimension = len(base['native-country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos definir as colunas com embedding\n",
    "colunas_rna = [age, embedded_workclass, final_weight, embedded_education, education_num,\n",
    "               embedded_marital, embedded_occupation, embedded_relationship, \n",
    "               embedded_race, embedded_sex,\n",
    "               capital_gain, capital_loos, hour, embedded_country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Natielle\\AppData\\Local\\Temp\\tmpwwr6oe18\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Natielle\\\\AppData\\\\Local\\\\Temp\\\\tmpwwr6oe18', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002208ED26898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2997: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2997: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Natielle\\AppData\\Local\\Temp\\tmpwwr6oe18\\model.ckpt.\n",
      "INFO:tensorflow:loss = 578753.3, step = 1\n",
      "INFO:tensorflow:global_step/sec: 181.833\n",
      "INFO:tensorflow:loss = 2337.0046, step = 101 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.996\n",
      "INFO:tensorflow:loss = 682.6166, step = 201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.619\n",
      "INFO:tensorflow:loss = 214.988, step = 301 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.315\n",
      "INFO:tensorflow:loss = 1192.1191, step = 401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.646\n",
      "INFO:tensorflow:loss = 1235.2029, step = 501 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.446\n",
      "INFO:tensorflow:loss = 1601.3296, step = 601 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.764\n",
      "INFO:tensorflow:loss = 357.98236, step = 701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.673\n",
      "INFO:tensorflow:loss = 774.3918, step = 801 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.892\n",
      "INFO:tensorflow:loss = 626.7122, step = 901 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.738\n",
      "INFO:tensorflow:loss = 1799.4341, step = 1001 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.613\n",
      "INFO:tensorflow:loss = 258.88553, step = 1101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.72\n",
      "INFO:tensorflow:loss = 427.64786, step = 1201 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.282\n",
      "INFO:tensorflow:loss = 628.6398, step = 1301 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.302\n",
      "INFO:tensorflow:loss = 528.44385, step = 1401 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.622\n",
      "INFO:tensorflow:loss = 3819.8809, step = 1501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.282\n",
      "INFO:tensorflow:loss = 516.81506, step = 1601 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.252\n",
      "INFO:tensorflow:loss = 1381.4727, step = 1701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 377\n",
      "INFO:tensorflow:loss = 681.4011, step = 1801 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.05\n",
      "INFO:tensorflow:loss = 1896.7816, step = 1901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.904\n",
      "INFO:tensorflow:loss = 659.3934, step = 2001 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.394\n",
      "INFO:tensorflow:loss = 245.82167, step = 2101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.107\n",
      "INFO:tensorflow:loss = 843.90344, step = 2201 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.257\n",
      "INFO:tensorflow:loss = 283.6175, step = 2301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.213\n",
      "INFO:tensorflow:loss = 549.7926, step = 2401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.906\n",
      "INFO:tensorflow:loss = 460.4684, step = 2501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.585\n",
      "INFO:tensorflow:loss = 261.14737, step = 2601 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.471\n",
      "INFO:tensorflow:loss = 294.93512, step = 2701 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.41\n",
      "INFO:tensorflow:loss = 167.95534, step = 2801 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.062\n",
      "INFO:tensorflow:loss = 422.72095, step = 2901 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.872\n",
      "INFO:tensorflow:loss = 234.7533, step = 3001 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.315\n",
      "INFO:tensorflow:loss = 175.93439, step = 3101 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.078\n",
      "INFO:tensorflow:loss = 1272.2568, step = 3201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.899\n",
      "INFO:tensorflow:loss = 538.719, step = 3301 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.554\n",
      "INFO:tensorflow:loss = 1571.5349, step = 3401 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.303\n",
      "INFO:tensorflow:loss = 706.3871, step = 3501 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.695\n",
      "INFO:tensorflow:loss = 321.48752, step = 3601 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.917\n",
      "INFO:tensorflow:loss = 144.56067, step = 3701 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.921\n",
      "INFO:tensorflow:loss = 259.68793, step = 3801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.472\n",
      "INFO:tensorflow:loss = 421.03693, step = 3901 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.322\n",
      "INFO:tensorflow:loss = 151.96776, step = 4001 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.852\n",
      "INFO:tensorflow:loss = 1742.3875, step = 4101 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.949\n",
      "INFO:tensorflow:loss = 220.36307, step = 4201 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.531\n",
      "INFO:tensorflow:loss = 114.89104, step = 4301 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.605\n",
      "INFO:tensorflow:loss = 356.36432, step = 4401 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.237\n",
      "INFO:tensorflow:loss = 116.32836, step = 4501 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.532\n",
      "INFO:tensorflow:loss = 460.068, step = 4601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.648\n",
      "INFO:tensorflow:loss = 211.8128, step = 4701 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.263\n",
      "INFO:tensorflow:loss = 121.0183, step = 4801 (0.247 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 384.227\n",
      "INFO:tensorflow:loss = 143.05055, step = 4901 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.701\n",
      "INFO:tensorflow:loss = 64.80531, step = 5001 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.471\n",
      "INFO:tensorflow:loss = 473.6425, step = 5101 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.2\n",
      "INFO:tensorflow:loss = 233.95566, step = 5201 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.735\n",
      "INFO:tensorflow:loss = 121.714066, step = 5301 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.155\n",
      "INFO:tensorflow:loss = 49.61904, step = 5401 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.643\n",
      "INFO:tensorflow:loss = 118.76278, step = 5501 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.547\n",
      "INFO:tensorflow:loss = 70.58853, step = 5601 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.514\n",
      "INFO:tensorflow:loss = 111.413124, step = 5701 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.392\n",
      "INFO:tensorflow:loss = 156.95445, step = 5801 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.501\n",
      "INFO:tensorflow:loss = 144.41667, step = 5901 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.444\n",
      "INFO:tensorflow:loss = 495.02216, step = 6001 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.56\n",
      "INFO:tensorflow:loss = 75.81485, step = 6101 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.995\n",
      "INFO:tensorflow:loss = 90.03459, step = 6201 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.742\n",
      "INFO:tensorflow:loss = 199.50098, step = 6301 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.467\n",
      "INFO:tensorflow:loss = 111.205925, step = 6401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.367\n",
      "INFO:tensorflow:loss = 137.112, step = 6501 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.734\n",
      "INFO:tensorflow:loss = 149.89178, step = 6601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.888\n",
      "INFO:tensorflow:loss = 259.6297, step = 6701 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.68\n",
      "INFO:tensorflow:loss = 148.46147, step = 6801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.288\n",
      "INFO:tensorflow:loss = 88.09743, step = 6901 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.117\n",
      "INFO:tensorflow:loss = 137.77583, step = 7001 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.842\n",
      "INFO:tensorflow:loss = 219.40292, step = 7101 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.61\n",
      "INFO:tensorflow:loss = 134.25731, step = 7201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.472\n",
      "INFO:tensorflow:loss = 82.23036, step = 7301 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.763\n",
      "INFO:tensorflow:loss = 325.0165, step = 7401 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.158\n",
      "INFO:tensorflow:loss = 1155.5248, step = 7501 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.151\n",
      "INFO:tensorflow:loss = 137.70767, step = 7601 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.61\n",
      "INFO:tensorflow:loss = 122.51051, step = 7701 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.566\n",
      "INFO:tensorflow:loss = 45.418884, step = 7801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.439\n",
      "INFO:tensorflow:loss = 257.7326, step = 7901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.747\n",
      "INFO:tensorflow:loss = 90.31407, step = 8001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.475\n",
      "INFO:tensorflow:loss = 254.97968, step = 8101 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.257\n",
      "INFO:tensorflow:loss = 105.49377, step = 8201 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.609\n",
      "INFO:tensorflow:loss = 114.03428, step = 8301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.628\n",
      "INFO:tensorflow:loss = 169.70631, step = 8401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.537\n",
      "INFO:tensorflow:loss = 161.28156, step = 8501 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.368\n",
      "INFO:tensorflow:loss = 397.9534, step = 8601 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.74\n",
      "INFO:tensorflow:loss = 75.18296, step = 8701 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.774\n",
      "INFO:tensorflow:loss = 131.71317, step = 8801 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.648\n",
      "INFO:tensorflow:loss = 79.581856, step = 8901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.307\n",
      "INFO:tensorflow:loss = 48.044395, step = 9001 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 30.778929, step = 9101 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.219\n",
      "INFO:tensorflow:loss = 146.41528, step = 9201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.93\n",
      "INFO:tensorflow:loss = 437.5727, step = 9301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.256\n",
      "INFO:tensorflow:loss = 123.815125, step = 9401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.457\n",
      "INFO:tensorflow:loss = 444.9696, step = 9501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.64\n",
      "INFO:tensorflow:loss = 196.46179, step = 9601 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.559\n",
      "INFO:tensorflow:loss = 9.20523, step = 9701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.936\n",
      "INFO:tensorflow:loss = 182.7512, step = 9801 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.266\n",
      "INFO:tensorflow:loss = 564.71313, step = 9901 (0.322 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\Natielle\\AppData\\Local\\Temp\\tmpwwr6oe18\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 172.8309.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x2208ed26080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora fazer de novo os passos para treinarmos o modelo (com o detalhe de que vamos usar a colunas_rna)\n",
    "\n",
    "# Vamos utilizar o estimator agora para implementarmos o modelo em si\n",
    "funcao_treinamento = tf.estimator.inputs.pandas_input_fn(x = X_train, y = Y_train,\n",
    "                                                        batch_size=32,# pega em lotes de 32\n",
    "                                                        num_epochs=None, # quantidade de vezes que vai rodar\n",
    "                                                        shuffle=True) # pega ordem aleatória\n",
    "\n",
    "# Criando nosso modelo com DNN  (dense neural network), que é quando todos neurônios estão ligados a todos da próxima camada\n",
    "classificador = tf.estimator.DNNClassifier(hidden_units = [8, 8], # quantidade de camadas ocultas e qtde de neurônios em cada\n",
    "                                           feature_columns=colunas_rna,  # passando as colunas\n",
    "                                           n_classes=2)  # maior que 50 mil ou menor. Temos duas categorias\n",
    "\n",
    "# Agora vamos fazer o treinamento\n",
    "classificador.train(input_fn = funcao_treinamento, steps = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que agora temos o treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-08T21:59:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Natielle\\AppData\\Local\\Temp\\tmpwwr6oe18\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-08-21:59:10\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.7225919, accuracy_baseline = 0.7582148, auc = 0.8110743, auc_precision_recall = 0.7012839, average_loss = 5.4838147, global_step = 10000, label/mean = 0.24178524, loss = 175.06989, precision = 0.46251616, prediction/mean = 0.47506657, recall = 0.9089754\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: C:\\Users\\Natielle\\AppData\\Local\\Temp\\tmpwwr6oe18\\model.ckpt-10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7225919,\n",
       " 'accuracy_baseline': 0.7582148,\n",
       " 'auc': 0.8110743,\n",
       " 'auc_precision_recall': 0.7012839,\n",
       " 'average_loss': 5.4838147,\n",
       " 'label/mean': 0.24178524,\n",
       " 'loss': 175.06989,\n",
       " 'precision': 0.46251616,\n",
       " 'prediction/mean': 0.47506657,\n",
       " 'recall': 0.9089754,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como já fizemos o treinamento, iremos fazer o teste agora\n",
    "\n",
    "# Criando a função para passarmos os dados do teste com tensorflow\n",
    "funcao_teste = tf.estimator.inputs.pandas_input_fn(x = X_test, y = Y_test, \n",
    "                                                   batch_size = 32,\n",
    "                                                   num_epochs = 1, \n",
    "                                                   shuffle = False)  # pega em ordem \n",
    "\n",
    "# Realizando de fato o teste do modelo\n",
    "classificador.evaluate(input_fn=funcao_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que a taxa de acerto (accuracy) é de 72% +-. O que é menor do que conseguimos atingir com a regresssão logística."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_py37",
   "language": "python",
   "name": "tensorflow2_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
