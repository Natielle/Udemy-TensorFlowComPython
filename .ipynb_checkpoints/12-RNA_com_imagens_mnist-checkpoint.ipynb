{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando a rede neural com imagens\n",
    "\n",
    "O objetivo é adivinhar qual é o dígito através da imagem.\n",
    "Banco de dados da Mnist. Pode ser encontrado em: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ba9add6ad390>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Lendo as imagens e fazendo download\n",
    "mnist = input_data.read_data_sets('mnist/', # As imagens ficarão nesse diretório \n",
    "                                  one_hot = True) # Faz a categorização \"binária\" de múltiplas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (55000, 784)\n",
      "X_test:  (10000, 784)\n",
      "Y_train:  (55000, 10)\n",
      "Y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados em treino e teste\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test  = mnist.test.images\n",
    "Y_test  = mnist.test.labels\n",
    "\n",
    "# Analisando as dimensões\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"Y_train: \", Y_train.shape)\n",
    "print(\"Y_test: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que as imagens possuem 28x28 de dimensão, logo as imagens possuem 28*28=784 atributos.\n",
    "\n",
    "Aliás, podemos ver abaixo que os dados já estão normalizados pois os valores vem em escala de 0 a 255. Então não vamos precisar normalizar o banco porque isso já está sendo realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# representação de uma imagem em formato de matriz\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe: 7')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agora vamos observar de fato alguma imagem carregada\n",
    "%matplotlib inline\n",
    "indice = 0\n",
    "plt.imshow(X_train[indice].reshape((28,28)), cmap = 'gray') # em esscala de cinza\n",
    "plt.title('Classe: ' + str(np.argmax(Y_train[indice])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe: 4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQe0lEQVR4nO3dfbBU9X3H8fdHuIAQtCJgCCKgwVZjJthcNVbbMWPiA1MHnY5pMI00Y4pptI1KMjqmbWj+aBkTNU6qTlGpmBqNiVKJY6qGPKBppF4Yoig+IKKCPEhQARPhAt/+sYf0infP3rtnd8/e/D6vmTu793z3nPNlh889Z/d3dn+KCMzs998BZTdgZq3hsJslwmE3S4TDbpYIh90sEQ67WSIc9t9DkuZI+s+y+7D24rAPUJIukNQlaYekDZJ+JOnUsvvqK0lDJD0raV3ZvaTCYR+AJF0BfAv4F+Aw4AjgJmB6mX3101eAzWU3kRKHfYCRdDDwdeCSiLgvIt6OiO6I+GFEfKXKOt+XtFHSW5KWSPpQj9o0Sc9I2i5pvaQvZ8tHS3pA0puStkp6VNIBWe0Dku6V9LqklyT9fT//DZOBvwL+td7nwfrPYR94TgaGAQv7sc6PgCnAWGA5cGeP2m3AxRExEjgO+Em2fDawDhhD5ezhaiCywP8Q+BUwHjgduEzSmQCSTpX0Zo1+vp1t77f9+DdYQQ77wHMosCUidvd1hYiYHxHbI2InMAf4SHaGANANHCvpoIh4IyKW91g+DpiYnTk8GpUPUpwAjImIr0fErohYA9wCfDrb12MR8QfVepF0HjA4Ivrzx8oawGEfeH4NjJY0uC8PljRI0lxJL0raBqzNSqOz278ApgEvS/q5pJOz5d8AVgMPS1oj6aps+UTgA9np/ZvZUfxqKkf/Wr2MAK4B/q4vvVtj9ek/jLWVXwLvAOcCP+jD4y+g8sbdJ6gE/WDgDUAAEfEEMF1SB3ApcA8wISK2UzmVn529xv+ppCeAV4GXImJKHb1PASYBj0oCGAIcLGkj8LGIWFvHNq2PfGQfYCLiLeCfgBslnStpuKQOSWdLuqaXVUYCO6mcEQyn8g4+8Lvhr89IOjgiuoFtwJ6s9ueSPqhKKvct3wP8L7BN0pWSDszOHI6TdEIf2l8JTACmZj+fBzZl91+t5/mwvnPYB6CIuA64AvgH4HUqQbkU+K9eHn4H8DKwHngGeHy/+meBtdkp/heovEsOlaPwj4EdVM4mboqIn0XEHuAcKgF9CdgC3ErljAFJfyppR5W+d0fExn0/wFZgb/b7nv4/E9Yf8pdXmKXBR3azRDjsZolw2M0S4bCbJaKl4+xDNDSGMaKVuzRLyju8za7Yqd5qhcIu6SzgBmAQcGtEzM17/DBGcJJOL7JLM8uxNBZXrdV9Gi9pEHAjcDZwLDBD0rH1bs/MmqvIa/YTgdURsSYidgF3M7A+T22WlCJhH8+7L3Fcly17F0mzsm9U6epmZ4HdmVkRRcLe25sA77kcLyLmRURnRHR2MLTA7sysiCJhX0flQw37HA68VqwdM2uWImF/ApgiabKkIVS+vGBRY9oys0are+gtInZLuhR4iMrQ2/yIeLphnZlZQxUaZ4+IB4EHG9SLmTWRL5c1S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiSg0ZbOktcB2YA+wOyI6G9GUmTVeobBnPh4RWxqwHTNrIp/GmyWiaNgDeFjSMkmzenuApFmSuiR1dbOz4O7MrF5FT+NPiYjXJI0FHpH0bEQs6fmAiJgHzAM4SKOi4P7MrE6FjuwR8Vp2uxlYCJzYiKbMrPHqDrukEZJG7rsPnAGsbFRjZtZYRU7jDwMWStq3ne9GxH83pCt7lwOGDcutH7FEVWs3jf9F7rqDlP/3ftWu3+TWZ595YW59z3Orc+vWOnWHPSLWAB9pYC9m1kQeejNLhMNulgiH3SwRDrtZIhx2s0Q04oMwVlCtobX1d0/OrT8w/s66933aynNz67p2dG596Isr6t53sw2edETV2u61r7Swk/bgI7tZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiPs7eB1XOOz60/e8KNdW97yuLP59b/8G+fy63vfXttbr3Mrx56ft4JufX7z/h21dpf3n5F7rpHzPmfunpqZz6ymyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJ8Dh7C8TJ+V/Cu+SCb9TYwvDc6iu7q3/d89EX5X+V/97uXTX2XZ7uT3w0t77wk/+WW/9Qx5BGtjPg+chulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXC4+wtsOnK/LHssYPyx9F/G/nrX3jZ7Kq14d1Lc9dtZzsu35Zb//CQjvz1Y2fV2uTv/zp33T251YGp5pFd0nxJmyWt7LFslKRHJL2Q3R7S3DbNrKi+nMbfDpy137KrgMURMQVYnP1uZm2sZtgjYgmwdb/F04EF2f0FQP4cQmZWunrfoDssIjYAZLdjqz1Q0ixJXZK6uqn+GsrMmqvp78ZHxLyI6IyIzg6GNnt3ZlZFvWHfJGkcQHa7uXEtmVkz1Bv2RcDM7P5M4P7GtGNmzVJznF3SXcBpwGhJ64CvAXOBeyRdBLwCnN/MJge6WUc/Vmj9857Lf3qHL6x/LF2D8/8L6MAD6952LXs+fGRu/fpj/qPQ9k9b9rmqtbFPP1to2wNRzbBHxIwqpdMb3IuZNZEvlzVLhMNulgiH3SwRDrtZIhx2s0T4I64DwMiOd3Lrb+fUus/ozF131D+uza1/78iHc+vF/LzQ2r/YmX+sGjPXV2z25CO7WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIRUTLdnaQRsVJSu/Dchsv/5Pc+vIv5089XOurpL/wyv7fB/r/bpv4SO66gxmUW29nU37wxfz6lx5vUSftY2ksZltsVW81H9nNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0T48+wt8Pbhewutf6CG5NYXTPxJTjV/HH32xhNz6w8+dEJuvXtc/jUAq8+4JbdexOjlvQ4nWxU+spslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmifA4ewsc/e+v59aP6b6kafv+4He25tb3Pvdibn3y7l/m1tfMPbnfPfXVF9efklsf9d1lufXWfVPDwFDzyC5pvqTNklb2WDZH0npJK7Kfac1t08yK6stp/O1Ab1+Fcn1ETM1+HmxsW2bWaDXDHhFLgPxzQTNre0XeoLtU0pPZaf4h1R4kaZakLkld3ewssDszK6LesN8MHAVMBTYA11Z7YETMi4jOiOjswBPtmZWlrrBHxKaI2BMRe4FbgPyPTplZ6eoKu6RxPX49D1hZ7bFm1h5qjrNLugs4DRgtaR3wNeA0SVOpDGWuBS5uYo8D3p7na4xlX5VfL7Tvpm25YvBvmveZ8q5bp+bWR3fnXwNg71Yz7BExo5fFtzWhFzNrIl8ua5YIh90sEQ67WSIcdrNEOOxmifBHXK0QFRjb211jYPCQ5315dSP5yG6WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcLj7FbI52Y8VPe6568+J7c+6GfL6962vZeP7GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIjzObrkGjRmTW58ydHXd295y86Tc+kg21r1tey8f2c0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRPRlyuYJwB3A+4G9wLyIuEHSKOB7wCQq0zZ/KiLeaF6rVoa3Pn5Ubv2c4fmfZ98R1b/7fdiW7rp6svr05ci+G5gdEccAHwMukXQscBWwOCKmAIuz382sTdUMe0RsiIjl2f3twCpgPDAdWJA9bAFwbrOaNLPi+vWaXdIk4HhgKXBYRGyAyh8EYGyjmzOzxulz2CW9D7gXuCwitvVjvVmSuiR1deO5u8zK0qewS+qgEvQ7I+K+bPEmSeOy+jhgc2/rRsS8iOiMiM4OhjaiZzOrQ82wSxJwG7AqIq7rUVoEzMzuzwTub3x7ZtYoffmI6ynAZ4GnJK3Ill0NzAXukXQR8ApwfnNatDLN/OdFhdZ/qbv68aTjx8sKbdv6p2bYI+IxQFXKpze2HTNrFl9BZ5YIh90sEQ67WSIcdrNEOOxmiXDYzRLhr5K2XIcO2lFo/W9uODOn+mahbVv/+MhulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXC4+zWVLv2Diq7Bcv4yG6WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcLj7NZUt0x6oGrto9denrvuUbMfb3Q7SfOR3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLRM1xdkkTgDuA9wN7gXkRcYOkOcDfAK9nD706Ih5sVqNWjq/e/Znc+h9deF1+vWNo9eLeajOBWzP05aKa3cDsiFguaSSwTNIjWe36iPhm89ozs0apGfaI2ABsyO5vl7QKGN/sxsyssfr1ml3SJOB4YGm26FJJT0qaL+mQKuvMktQlqaubnYWaNbP69Tnskt4H3AtcFhHbgJuBo4CpVI781/a2XkTMi4jOiOjsIOf1m5k1VZ/CLqmDStDvjIj7ACJiU0TsiYi9wC3Aic1r08yKqhl2SQJuA1ZFxHU9lo/r8bDzgJWNb8/MGkURkf8A6VTgUeApKkNvAFcDM6icwgewFrg4ezOvqoM0Kk7S6QVbNrNqlsZitsXWXsc0+/Ju/GNAbyt7TN1sAPEVdGaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRNT/P3tCdSa8DL/dYNBrY0rIG+qdde2vXvsC91auRvU2MiDG9FVoa9vfsXOqKiM7SGsjRrr21a1/g3urVqt58Gm+WCIfdLBFlh31eyfvP0669tWtf4N7q1ZLeSn3NbmatU/aR3cxaxGE3S0QpYZd0lqTnJK2WdFUZPVQjaa2kpyStkNRVci/zJW2WtLLHslGSHpH0Qnbb6xx7JfU2R9L67LlbIWlaSb1NkPRTSaskPS3pS9nyUp+7nL5a8ry1/DW7pEHA88AngXXAE8CMiHimpY1UIWkt0BkRpV+AIenPgB3AHRFxXLbsGmBrRMzN/lAeEhFXtklvc4AdZU/jnc1WNK7nNOPAucBfU+Jzl9PXp2jB81bGkf1EYHVErImIXcDdwPQS+mh7EbEE2Lrf4unAguz+Air/WVquSm9tISI2RMTy7P52YN8046U+dzl9tUQZYR8PvNrj93W013zvATwsaZmkWWU304vD9k2zld2OLbmf/dWcxruV9ptmvG2eu3qmPy+qjLD3NpVUO43/nRIRfwycDVySna5a3/RpGu9W6WWa8bZQ7/TnRZUR9nXAhB6/Hw68VkIfvYqI17LbzcBC2m8q6k37ZtDNbjeX3M/vtNM03r1NM04bPHdlTn9eRtifAKZImixpCPBpYFEJfbyHpBHZGydIGgGcQftNRb0ImJndnwncX2Iv79Iu03hXm2ackp+70qc/j4iW/wDTqLwj/yLw1TJ6qNLXkcCvsp+ny+4NuIvKaV03lTOii4BDgcXAC9ntqDbq7TtUpvZ+kkqwxpXU26lUXho+CazIfqaV/dzl9NWS582Xy5olwlfQmSXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJ+D8xJQfLGEL/jwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "indice = 2\n",
    "plt.imshow(X_train[indice].reshape((28,28))) # Sem o filtro de cinza\n",
    "plt.title('Classe: ' + str(np.argmax(Y_train[indice])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, Y_batch = mnist.train.next_batch(128) # separamos o batch_size com 128 imagens\n",
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Quantidade de neurônios de entrada:  784\n",
      "\n",
      " Quantidade de neurônios de oculta 1:  397\n",
      "\n",
      " Quantidade de neurônios de oculta 2:  397\n",
      "\n",
      " Quantidade de neurônios de oculta 3:  397\n",
      "\n",
      " Quantidade de neurônios de saida:  10\n"
     ]
    }
   ],
   "source": [
    "# Vamos definir os neurônios da rede neural agora\n",
    "\n",
    "# Camada de entrada\n",
    "neuronios_entrada = X_train.shape[1]\n",
    "print(\"\\n Quantidade de neurônios de entrada: \", neuronios_entrada)\n",
    "\n",
    "# Camadas ocultas, nesse caso iremos utilizar 3\n",
    "neuronios_oculta1 = int((X_train.shape[1] + Y_train.shape[1]) / 2)\n",
    "print(\"\\n Quantidade de neurônios de oculta 1: \", neuronios_oculta1)\n",
    "\n",
    "neuronios_oculta2 = neuronios_oculta1\n",
    "print(\"\\n Quantidade de neurônios de oculta 2: \", neuronios_oculta2)\n",
    "\n",
    "neuronios_oculta3 = neuronios_oculta1\n",
    "print(\"\\n Quantidade de neurônios de oculta 3: \", neuronios_oculta3)\n",
    "\n",
    "# Camada de saída\n",
    "neuronios_saida = Y_train.shape[1]\n",
    "print(\"\\n Quantidade de neurônios de saida: \", neuronios_saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observações:**\n",
    "\n",
    "- Podemos considerar deep learning as redes neurais que posssuem, aproximadamente, mais do que duas camadas ocultas.\n",
    "- A quantidade de neurônios de entrada é a quantidade de atributos da imagem (28*28 = 784)\n",
    "- A quantidade de neurônios de saída é a quantidade de labels que queremos adivinhar. Ou seja, números de 0 a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Natielle\\anaconda3\\envs\\tensorflow2_py37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Portanto precisaremos definir os pesos e os bias\n",
    "\n",
    "W = {'oculta1': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta1, neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta2, neuronios_oculta3])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_oculta3, neuronios_saida])) \n",
    "}\n",
    "\n",
    "B = {'oculta1': tf.Variable(tf.random_normal([neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta3])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " W:  {'oculta1': <tf.Variable 'Variable:0' shape=(784, 397) dtype=float32_ref>, 'oculta2': <tf.Variable 'Variable_1:0' shape=(397, 397) dtype=float32_ref>, 'oculta3': <tf.Variable 'Variable_2:0' shape=(397, 397) dtype=float32_ref>, 'saida': <tf.Variable 'Variable_3:0' shape=(397, 10) dtype=float32_ref>}\n",
      "\n",
      "\n",
      " type(W['oculta1']):  <class 'tensorflow.python.ops.variables.RefVariable'>\n",
      "\n",
      "\n",
      " W['oculta1']:  <tf.Variable 'Variable:0' shape=(784, 397) dtype=float32_ref>\n",
      "\n",
      " B:  {'oculta1': <tf.Variable 'Variable_4:0' shape=(397,) dtype=float32_ref>, 'oculta2': <tf.Variable 'Variable_5:0' shape=(397,) dtype=float32_ref>, 'oculta3': <tf.Variable 'Variable_6:0' shape=(397,) dtype=float32_ref>, 'saida': <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>}\n",
      "\n",
      "\n",
      " type(B['oculta1']):  <class 'tensorflow.python.ops.variables.RefVariable'>\n",
      "\n",
      "\n",
      " B['oculta']:  <tf.Variable 'Variable_4:0' shape=(397,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os tipos das variáveis\n",
    "print(\"\\n W: \", W)\n",
    "print(\"\\n\\n type(W['oculta1']): \", type(W['oculta1']))\n",
    "print(\"\\n\\n W[\\'oculta1\\']: \", W['oculta1'])\n",
    "\n",
    "# Visualizando os tipos das variáveis\n",
    "print(\"\\n B: \", B)\n",
    "print(\"\\n\\n type(B['oculta1']): \", type(B['oculta1']))\n",
    "print(\"\\n\\n B[\\'oculta\\']: \", B['oculta1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os placeholders que irão receber os dados\n",
    "xph = tf.placeholder('float', [None, neuronios_entrada]) # None -> não importa a quantidade de linhas na dimensão \n",
    "yph = tf.placeholder('float', [None, neuronios_saida])   # None -> não importa a quantidade de linhas na dimensão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(xph) \n",
    "print(yph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo de feed foward\n",
    "def mlp(x, W, bias):\n",
    "    # Vamos utilizar a função de ativação relu -> f(x) = max(0,x)\n",
    "    camada_oculta1 = tf.nn.relu(tf.add(tf.matmul(x, W['oculta1']), bias['oculta1']))\n",
    "    camada_oculta2 = tf.nn.relu(tf.add(tf.matmul(camada_oculta1, W['oculta2']), bias['oculta2']))\n",
    "    camada_oculta3 = tf.nn.relu(tf.add(tf.matmul(camada_oculta2, W['oculta3']), bias['oculta3']))\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta3, W['saida']), bias['saida'])\n",
    "    \n",
    "    # Nota: ainda não aplicamos a função de ativação na camada de saída\n",
    "    # Nota que sempre estamos adicionando o bias\n",
    "    \n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = mlp(xph, W, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro inicial:  Tensor(\"Mean_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Então vamos calcular o erro\n",
    "# logits -> previsões do modelo; label -> classes corretas\n",
    "# E não precisamos aplicar a função softmax depois porque ela já é aplicada aqui\n",
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "print(\"Erro inicial: \", erro) # Podemos confirmar que será um número escalar\n",
    "\n",
    "# Vamos minimizar os erros com o otimizador Adam ao invés de usar o gradiente descendente \n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender um pouco melhor o que está sendo feito, podemos olhar a figura a seguir:\n",
    "\n",
    "![](softmax_CE_pipeline.png)\n",
    "\n",
    "Nota-se que:\n",
    "- CE: Cross Entropy\n",
    "- É preferível trabalhar com a Cross Entropy em deep learning do que com a MSE porque o número elevado ao quadrado no MSE pode deixar o processamento mais lento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "época: 1 erro: 65431.816\n",
      "época: 101 erro: 20860.05\n",
      "época: 201 erro: 11099.249\n",
      "época: 301 erro: 8189.3022\n",
      "época: 401 erro: 6204.449\n",
      "época: 501 erro: 4396.2617\n",
      "época: 601 erro: 3586.929\n",
      "época: 701 erro: 3396.566\n",
      "época: 801 erro: 3592.3438\n",
      "época: 901 erro: 2021.584\n",
      "época: 1001 erro: 3241.6436\n",
      "época: 1101 erro: 1733.7134\n",
      "época: 1201 erro: 1692.2202\n",
      "época: 1301 erro: 1510.6772\n",
      "época: 1401 erro: 1852.7744\n",
      "época: 1501 erro: 1848.2762\n",
      "época: 1601 erro: 1154.8455\n",
      "época: 1701 erro: 1767.9495\n",
      "época: 1801 erro: 784.161\n",
      "época: 1901 erro: 1837.6746\n",
      "época: 2001 erro: 522.1771\n",
      "época: 2101 erro: 1261.4734\n",
      "época: 2201 erro: 1461.5529\n",
      "época: 2301 erro: 1165.7201\n",
      "época: 2401 erro: 1329.8939\n",
      "época: 2501 erro: 1285.7783\n",
      "época: 2601 erro: 1087.8186\n",
      "época: 2701 erro: 703.30493\n",
      "época: 2801 erro: 940.7085\n",
      "época: 2901 erro: 616.9698\n",
      "época: 3001 erro: 517.59656\n",
      "época: 3101 erro: 1009.2645\n",
      "época: 3201 erro: 739.3825\n",
      "época: 3301 erro: 724.0027\n",
      "época: 3401 erro: 1033.6606\n",
      "época: 3501 erro: 636.75885\n",
      "época: 3601 erro: 697.7854\n",
      "época: 3701 erro: 751.0992\n",
      "época: 3801 erro: 821.196\n",
      "época: 3901 erro: 594.8542\n",
      "época: 4001 erro: 900.7344\n",
      "época: 4101 erro: 596.5187\n",
      "época: 4201 erro: 584.25366\n",
      "época: 4301 erro: 128.96677\n",
      "época: 4401 erro: 359.01392\n",
      "época: 4501 erro: 756.40295\n",
      "época: 4601 erro: 789.3636\n",
      "época: 4701 erro: 329.8913\n",
      "época: 4801 erro: 1075.0476\n",
      "época: 4901 erro: 553.0889\n",
      "Treinamento concluído\n"
     ]
    }
   ],
   "source": [
    "# Agora vamos realizar as épocas para treinar o modelo\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoca in range(5000):\n",
    "        # Vamos fazer o processamento de lote em lote, nesse caso é em lote de 128.\n",
    "        X_batch, Y_batch = mnist.train.next_batch(128)\n",
    "        \n",
    "        _, custo = sess.run([otimizador, erro], feed_dict = {xph: X_batch, yph: Y_batch})\n",
    "        \n",
    "        if epoca % 100 == 0:\n",
    "            print('época: ' + str((epoca + 1)) + ' erro: ' + str(custo))\n",
    "            \n",
    "    print('Treinamento concluído')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões Tensor(\"Softmax_3:0\", shape=(?, 10), dtype=float32)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Agora vamos fazer as previsões\n",
    "previsoes = tf.nn.softmax(modelo)\n",
    "print(\"Previsões\", previsoes)\n",
    "\n",
    "# podemos ver os valores dentro de uma sessão também\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(previsoes, feed_dict= {xph: X_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, podemos observar os labels previstos estão no formato de categorização \"binária\" (oneHotEncoder). Então vamos converter os labels em números de 0 a 9, que é o que queremos prever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_9:0\", shape=(?,), dtype=int64)\n",
      "[2 1 1 ... 7 2 7]\n"
     ]
    }
   ],
   "source": [
    "previsoes_corretas_labels = tf.argmax(previsoes, 1)\n",
    "print(previsoes_corretas_labels)\n",
    "\n",
    "# podemos ver os valores dentro de uma sessão também\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(previsoes_corretas_labels, feed_dict= {xph: X_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim temos que a 1° e 2° imagem é o número 4 e assim por diante...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False  True]\n"
     ]
    }
   ],
   "source": [
    "# Agora vamos fazer um comparativo das previsões com o que é realmente\n",
    "previsoes_corretas_bool = tf.equal(previsoes_corretas_labels, tf.argmax(yph, 1))\n",
    "\n",
    "# podemos ver os valores dentro de uma sessão também\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(previsoes_corretas_bool, feed_dict= {xph: X_test, yph: Y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que ele retorna se a previsão feita está correta ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "época: 1 erro: 52063.316 acc: [0.0234375]\n",
      "época: 101 erro: 16807.594 acc: [0.2265625]\n",
      "época: 201 erro: 8900.271 acc: [0.3359375]\n",
      "época: 301 erro: 5236.3135 acc: [0.4921875]\n",
      "época: 401 erro: 4095.3142 acc: [0.5390625]\n",
      "época: 501 erro: 3963.2349 acc: [0.609375]\n",
      "época: 601 erro: 3594.1694 acc: [0.6328125]\n",
      "época: 701 erro: 2848.9712 acc: [0.7109375]\n",
      "época: 801 erro: 2513.4778 acc: [0.703125]\n",
      "época: 901 erro: 2230.3599 acc: [0.75]\n",
      "época: 1001 erro: 2712.2393 acc: [0.6875]\n",
      "época: 1101 erro: 2211.754 acc: [0.71875]\n",
      "época: 1201 erro: 1885.077 acc: [0.7578125]\n",
      "época: 1301 erro: 1580.5377 acc: [0.8125]\n",
      "época: 1401 erro: 1487.129 acc: [0.8046875]\n",
      "época: 1501 erro: 1865.7029 acc: [0.7734375]\n",
      "época: 1601 erro: 1733.6587 acc: [0.765625]\n",
      "época: 1701 erro: 1085.3037 acc: [0.8359375]\n",
      "época: 1801 erro: 1479.6613 acc: [0.8359375]\n",
      "época: 1901 erro: 1324.1008 acc: [0.8203125]\n",
      "época: 2001 erro: 1368.9297 acc: [0.84375]\n",
      "época: 2101 erro: 1299.4852 acc: [0.859375]\n",
      "época: 2201 erro: 1363.2285 acc: [0.8125]\n",
      "época: 2301 erro: 1456.0938 acc: [0.828125]\n",
      "época: 2401 erro: 1040.0386 acc: [0.8359375]\n",
      "época: 2501 erro: 495.98502 acc: [0.921875]\n",
      "época: 2601 erro: 918.93567 acc: [0.8515625]\n",
      "época: 2701 erro: 1166.2928 acc: [0.8203125]\n",
      "época: 2801 erro: 674.02637 acc: [0.90625]\n",
      "época: 2901 erro: 488.31818 acc: [0.875]\n",
      "época: 3001 erro: 989.5135 acc: [0.8515625]\n",
      "época: 3101 erro: 1315.031 acc: [0.8671875]\n",
      "época: 3201 erro: 504.72125 acc: [0.8984375]\n",
      "época: 3301 erro: 702.0482 acc: [0.9140625]\n",
      "época: 3401 erro: 779.2142 acc: [0.859375]\n",
      "época: 3501 erro: 877.391 acc: [0.859375]\n",
      "época: 3601 erro: 1209.3679 acc: [0.84375]\n",
      "época: 3701 erro: 726.1251 acc: [0.8828125]\n",
      "época: 3801 erro: 579.4319 acc: [0.921875]\n",
      "época: 3901 erro: 608.5316 acc: [0.875]\n",
      "época: 4001 erro: 983.08264 acc: [0.90625]\n",
      "época: 4101 erro: 928.31445 acc: [0.8671875]\n",
      "época: 4201 erro: 595.12555 acc: [0.921875]\n",
      "época: 4301 erro: 399.8633 acc: [0.921875]\n",
      "época: 4401 erro: 419.2808 acc: [0.9375]\n",
      "época: 4501 erro: 593.74146 acc: [0.8984375]\n",
      "época: 4601 erro: 490.2112 acc: [0.9140625]\n",
      "época: 4701 erro: 870.0254 acc: [0.890625]\n",
      "época: 4801 erro: 675.17645 acc: [0.9296875]\n",
      "época: 4901 erro: 805.91174 acc: [0.8828125]\n",
      "Treinamento concluído\n",
      "0.896\n"
     ]
    }
   ],
   "source": [
    "# Com isso, podemos calcular a taxa de acerto\n",
    "# tf.cast -> faz a conversão do booleando para tf.float32\n",
    "taxa_acerto = tf.reduce_mean(tf.cast(previsoes_corretas_bool, tf.float32))\n",
    "\n",
    "# Podemos visualizar a taxa de acerto enquanto formos treinando também dentro de uma \n",
    "# sesão pois já temos as fórmulas definidas\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoca in range(5000):\n",
    "        X_batch, Y_batch = mnist.train.next_batch(128)\n",
    "        _, custo = sess.run([otimizador, erro], feed_dict = {xph: X_batch, yph: Y_batch})\n",
    "        if epoca % 100 == 0:\n",
    "            acc = sess.run([taxa_acerto], feed_dict = {xph: X_batch, yph: Y_batch})\n",
    "            print('época: ' + str((epoca + 1)) + ' erro: ' + str(custo) + ' acc: ' + str(acc))\n",
    "            \n",
    "    print('Treinamento concluído')\n",
    "    print(sess.run(taxa_acerto, feed_dict = {xph: X_test, yph: Y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando treinamos e já vamos mostrando as métricas, podemos notar que taxa de acerto vai aumentando e o erro vai diminuindo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_py37",
   "language": "python",
   "name": "tensorflow2_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
