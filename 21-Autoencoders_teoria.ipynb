{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "É utilizado para reduzir a dimensionalidade dos dados. Isso acaba sendo muito útil no processamento de imagens por permitir um esforço computacional menor, ao aplicar a redução de dimensão de uma imagem.\n",
    "\n",
    "Na imagem abaixo podemos notar que a quantidade de neurônios de entrada é igual a quantidade de saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo do autoencoder em imagens: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](autoencoder_image_example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coisas importantes:\n",
    "\n",
    "- O auto enconder é um método não supervisionado. \n",
    "\n",
    "Pois não teremos os labels/rótulos do dados.\n",
    "\n",
    "- Self supervised learning. É um tipo de algoritmo que ele mesmo aprende sozinho.\n",
    "\n",
    "- **Caso o autoencoder tenha X entradas, ele NECESSARIAMENTE tem que ter X saídas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Sparse autoencoder\n",
    "\n",
    "- É um dos mais populares. \n",
    "\n",
    "- Nele temos que a quantidade de neurônios da camada oculta é maior do que a quantidade de neurônios da camada de entrada e da camada de saída. \n",
    "\n",
    "- Não utiliza todos os neurônios da camada oculta. O algoritmo desconsidera aleatoriamente alguns neurônios em cada rodada, o que ajuda na prevenção de overfitting.\n",
    "\n",
    "- Usa uma técnica de regularização para prevenir o overfitting. Pois poderia haver um overfitting dado que temos mais neurônios na camada oculta do que na camada de entrada.\n",
    "\n",
    "A figura abaixo mostra esse tipo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sparse_autoencoder.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder\n",
    "\n",
    "Aqui a quantidade de neurônios da camada oculta é a mesma quantidade de neurônios de entrada.\n",
    "\n",
    "Nos algoritmos de aprendizado supervisionado, para calcularmos o erro comparamos a saída prevista com uma saída que já foi rotulada. Aqui será diferente, para calcular o erro iremos comparar as entradas com as saídas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](denoising_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Legenda:**\n",
    "\n",
    "Pirâmide -> significa que alguns neurônios aleatórios da camada de entrada serão zerados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractive Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele adiciona uma função de penalidade quando os pesos são atualizados, fazendo o backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep autoencoder (ou stack)\n",
    "\n",
    "Aqui vamos fazendo o enconde dos dados e depois realizamos o decoder nas mesmas proporções.\n",
    "\n",
    "Exemplo: Se reduziu de 3 neurônios pra 2 ao fazer o encode, então vamos fazer de 2 para 3 quando realizarmos o decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](deep_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional autoencoder\n",
    "\n",
    "É baseado na convolução. Vamos reduzindo a dimensionalidade ao realizar as convoluções e depois é realizada a deconvolução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](convolutional_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo sobre redes neurais e suas arquiteturas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](neural_network_complete.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_py37",
   "language": "python",
   "name": "tensorflow2_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
